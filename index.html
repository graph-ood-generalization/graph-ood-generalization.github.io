<!DOCTYPE html>
<html>
<meta name="description" content="Graph OOD survey page">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<head>
    <title>Graph OOD Generalization</title>
</head>

<body>
<div id="layout-content" style="margin-top:25px">

<table>
    <tbody>
        <tr>
            <td width="1000">
                <div id="toptitle">
                    <h1>Out-Of-Distribution Generalization on Graphs: Paper List</h1>
                </div>
            </td>
        </tr>
    </tbody>
</table>



Summarized by <i>Lab of Media and Network, Department of Computer Science and Technology, Tsinghua University</i>


<h2>Overview</h2>
<p>
    Paper list of <b>Graph Out-of-Distribution Generalization</b>. The existing literature can be summarized into three categories from conceptually different perspectives, i.e., <i>data</i>, <i>model</i>, and <i>learning strategy</i>, based on their positions in the graph machine learning pipeline. For more details, please refer to our survey paper <b><a href="https://arxiv.org/abs/2202.07987">Out-Of-Distribution Generalization on Graphs: A Survey</a></b>.
</p>



<div id='write'  class=''><h2 id='data'><span>Data</span></h2><h4 id='graph-data-augmentation'><span>Graph Data Augmentation</span></h4><ul><li><span>[NeurIPS 2021] Metropolis-Hastings Data Augmentation for Graph Neural Networks </span><a href='https://proceedings.neurips.cc/paper/2021/file/9e7ba617ad9e69b39bd0c29335b79629-Paper.pdf'><span>[paper]</span></a></li><li><span>[AAAI 2021] Data Augmentation for Graph Neural Networks </span><a href='https://arxiv.org/pdf/2006.06830.pdf'><span>[paper]</span></a></li><li><span>[arXiv 2020] FLAG: Adversarial Data Augmentation for Graph Neural Networks </span><a href='https://arxiv.org/pdf/2010.09891.pdf'><span>[paper]</span></a></li><li><span>[NeurIPS 2020] Graph Random Neural Network for Semi-Supervised Learning on Graphs </span><a href='https://arxiv.org/pdf/2005.11079.pdf'><span>[paper]</span></a></li><li><span>[ICLR 2020] DropEdge: Towards Deep Graph Convolutional Networks on Node Classification </span><a href='https://arxiv.org/pdf/1907.10903.pdf'><span>[paper]</span></a></li></ul><h2 id='model'><span>Model</span></h2><h4 id='disentanglement-based-graph-models'><span>Disentanglement-based Graph Models</span></h4><ul><li><span>[NeurIPS 2021] Disentangled Contrastive Learning on Graphs </span><a href='https://openreview.net/pdf?id=C_L0Xw_Qf8M'><span>[paper]</span></a></li></ul><ul><li><span>[AAAI 2020] Independence Promoted Graph Disentangled Networks </span><a href='https://arxiv.org/pdf/1911.11430.pdf'><span>[paper]</span></a></li><li><span>[NeurIPS 2020] Factorizable graph convolutional networks </span><a href='https://arxiv.org/pdf/2010.05421.pdf'><span>[paper]</span></a></li><li><span>[KDD 2020] Interpretable deep graph generation with node-edge co-disentanglement </span><a href='https://arxiv.org/pdf/2006.05385.pdf'><span>[paper]</span></a></li><li><span>[ICML 2019] Disentangled Graph Convolutional Networks </span><a href='http://proceedings.mlr.press/v97/ma19a/ma19a.pdf'><span>[paper]</span></a></li><li><span>[ICANN 2018] GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders </span><a href='https://arxiv.org/pdf/1802.03480.pdf'><span>[paper]</span></a></li><li><span>[NeurIPS Workshop 2016] Variational Graph Auto-Encoders </span><a href='https://arxiv.org/pdf/1611.07308.pdf'><span>[paper]</span></a></li></ul><h4 id='causality-based-graph-models'><span>Causality-based Graph Models</span></h4><ul><li><span>[arXiv 2022] Deconfounding to Explanation Evaluation in Graph Neural Networks </span><a href='https://arxiv.org/pdf/2201.08802.pdf'><span>[paper]</span></a></li><li><span>[arXiv 2021] OOD-GNN: Out-of-Distribution Generalized Graph Neural Network </span><a href='https://arxiv.org/abs/2112.03806'><span>[paper]</span></a><span> </span></li></ul><ul><li><span>[TNNLS] Debiased Graph Neural Networks with Agnostic Label Selection Bias </span><a href='https://arxiv.org/abs/2201.07708'><span>[paper]</span></a></li><li><span>[arXiv 2021] Generalizing Graph Neural Networks on Out-Of-Distribution Graphs </span><a href='https://arxiv.org/abs/2111.10657'><span>[paper]</span></a><span> </span></li><li><span>[arXiv 2021] Deconfounded Training for Graph Neural Networks </span><a href='https://arxiv.org/pdf/2112.15089.pdf'><span>[paper]</span></a></li><li><span>[arXiv 2021] Counterfactual Graph Learning for Link Prediction </span><a href='https://arxiv.org/abs/2106.02172'><span>[paper]</span></a></li><li><span>[ICML 2021] Generative Causal Explanations for Graph Neural Networks </span><a href='https://arxiv.org/pdf/2104.06643.pdf'><span>[paper]</span></a></li><li><span>[ICML 2021] Size-Invariant Graph Representations for Graph Classification Extrapolations </span><a href='https://arxiv.org/abs/2103.05045'><span>[paper]</span></a></li></ul><h2 id='learning-strategy'><span>Learning Strategy</span></h2><h4 id='graph-invariant-learning'><span>Graph Invariant Learning</span></h4><ul><li><span>[ICLR 2022] Towards Distribution Shift of Node-Level Prediction on Graphs: An Invariance Perspective </span><a href='https://openreview.net/pdf?id=FQOC5u-1egI'><span>[paper]</span></a><span> </span></li><li><span>[ICLR 2022] Discovering Invariant Rationales for Graph Neural Networks </span><a href='https://arxiv.org/pdf/2201.12872.pdf'><span>[paper]</span></a></li><li><span>[NeurIPS 2021] Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training Data </span><a href='https://arxiv.org/pdf/2108.01099.pdf'><span>[paper]</span></a></li><li><span>[arXiv 2021] Stable Prediction on Graphs with Agnostic Distribution Shift </span><a href='https://arxiv.org/pdf/2110.03865.pdf'><span>[paper]</span></a></li></ul><h4 id='graph-adversarial-training'><span>Graph Adversarial Training</span></h4><ul><li><span>[arXiv 2021] CAP: Co-Adversarial Perturbation on Weights and Features for Improving Generalization of Graph Neural Networks </span><a href='https://arxiv.org/pdf/2110.14855.pdf'><span>[paper]</span></a><span> </span></li><li><span>[arXiv 2021] Distributionally Robust Semi-Supervised Learning Over Graphs </span><a href='https://arxiv.org/pdf/2110.10582.pdf'><span>[paper]</span></a><span> </span></li><li><span>[Openreview 2021] Adversarial Weight Perturbation Improves Generalization in Graph Neural Networks </span><a href='https://openreview.net/pdf?id=hUr6K4D9f7P'><span>[paper]</span></a><span> </span></li><li><span>[TKDE] Graph Adversarial Training: Dynamically Regularizing Based on Graph Structure </span><a href='https://arxiv.org/pdf/1902.08226.pdf'><span>[paper]</span></a></li><li><span>[ICDM 2019] Domain-Adversarial Graph Neural Networks for Text Classification </span><a href='https://shiruipan.github.io/publication/icdm-19-wu/icdm-19-wu.pdf'><span>[paper]</span></a><span> </span></li></ul><h4 id='graph-self-supervised-learning'><span>Graph Self-supervised Learning</span></h4><ul><li><span>[WWW 2022] Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift </span><a href='https://arxiv.org/pdf/2201.11349.pdf'><span>[paper]</span></a></li><li><span>[arXiv 2021] Graph Self-Supervised Learning: A Survey </span><a href='https://arxiv.org/pdf/2103.00111.pdf'><span>[paper]</span></a></li><li><span>[ICML 2021] From Local Structures to Size Generalization in Graph Neural Networks </span><a href='https://arxiv.org/pdf/2010.08853.pdf'><span>[paper]</span></a><span> </span></li><li><span>[NeurIPS 2020] Graph Contrastive Learning with Augmentations </span><a href='https://arxiv.org/pdf/2010.13902.pdf'><span>[paper]</span></a></li><li><span>[ICLR 2020] Strategies for Pre-training Graph Neural Networks </span><a href='https://arxiv.org/pdf/1905.12265.pdf'><span>[paper]</span></a></li><li><span>[KDD 2020] GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training </span><a href='https://arxiv.org/pdf/2006.09963.pdf'><span>[paper]</span></a></li></ul><h2 id='theory'><span>Theory</span></h2><ul><li><span>[NeurIPS 2021] Subgroup Generalization and Fairness of Graph Neural Networks </span><a href='https://arxiv.org/pdf/2106.15535.pdf'><span>[paper]</span></a></li><li><span>[NeurIPS 2021] Learning Theory Can (Sometimes) Explain Generalisation in Graph Neural Networks </span><a href='https://arxiv.org/pdf/2112.03968.pdf'><span>[paper]</span></a></li><li><span>[ICLR 2021] How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks </span><a href='https://arxiv.org/abs/2009.11848'><span>[paper]</span></a></li><li><span>[ICLR 2021] A pac-bayesian approach to generalization bounds for graph neural networks </span><a href='https://arxiv.org/pdf/2012.07690.pdf'><span>[paper]</span></a></li><li><span>[arXiv 2021] Generalization bounds for graph convolutional neural networks via Rademacher complexity </span><a href='https://arxiv.org/pdf/2102.10234.pdf'><span>[paper]</span></a></li><li><span>[ICML 2021] Graph Convolution for Semi-Supervised Classification Improved Linear Separability and Out-of-Distribution Generalization </span><a href='https://arxiv.org/pdf/2102.06966.pdf'><span>[paper]</span></a></li><li><span>[ICML 2020 WorkShop] From Graph Low-Rank Global Attention to 2-FWL Approximation </span><a href='https://grlplus.github.io/papers/92.pdf'><span>[paper]</span></a></li><li><span>[ICML 2020] Generalization and Representational Limits of Graph Neural Networks </span><a href='https://arxiv.org/pdf/2002.06157.pdf'><span>[paper]</span></a></li><li><span>[NeurIPS 2019] Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph Kernels  </span><a href='https://arxiv.org/pdf/1905.13192.pdf'><span>[paper]</span></a></li><li><span>[KDD 2019] Stability and Generalization of Graph Convolutional Neural Networks </span><a href='https://arxiv.org/pdf/1905.01004.pdf'><span>[paper]</span></a></li><li><span>[Neural Networks] The Vapnikâ€“Chervonenkis dimension of graph and recursive neural networks </span><a href='https://www.sciencedirect.com/science/article/abs/pii/S0893608018302363'><span>[paper]</span></a></li></ul><h2 id='other-related-papers'><span>Other Related Papers</span></h2><h4 id='gnn-architecture'><span>GNN Architecture</span></h4><ul><li><span>[arXiv 2021] Learning to Pool in Graph Neural Networks for Extrapolation </span><a href='https://arxiv.org/pdf/2106.06210.pdf'><span>[paper]</span></a></li><li><span>[ICLR 2020] What Can Neural Networks Reason About? </span><a href='https://arxiv.org/pdf/1905.13211.pdf'><span>[paper]</span></a></li><li><span>[ICLR 2020] Neural Execution of Graph Algorithms </span><a href='https://arxiv.org/pdf/1910.10593.pdf'><span>[paper]</span></a></li><li><span>[NeurIPS 2019] Understanding Attention and Generalization in Graph Neural Networks </span><a href='https://arxiv.org/pdf/1905.02850.pdf'><span>[paper]</span></a></li><li><span>[arXiv 2020] Customized Graph Neural Networks </span><a href='https://arxiv.org/pdf/2005.12386.pdf'><span>[paper]</span></a></li></ul><h4 id='dynamic-environment'><span>Dynamic Environment</span></h4><ul><li><span>[arXiv 2021] Online Adversarial Distillation for Graph Neural Networks </span><a href='https://arxiv.org/pdf/2112.13966.pdf'><span>[paper]</span></a></li><li><span>[IJCNN 2021] Lifelong Learning of Graph Neural Networks for Open-World Node Classification </span><a href='https://arxiv.org/pdf/2006.14422.pdf'><span>[paper]</span></a></li></ul><h4 id='domain-knowledge'><span>Domain Knowledge</span></h4><ul><li><span>[AAAI 2022] How Does Knowledge Graph Embedding Extrapolate to Unseen Data: a Semantic Evidence View </span><a href='https://arxiv.org/pdf/2109.11800.pdf'><span>[paper]</span></a></li><li><span>[NeurIPS 2021 Workshop] Reliable Graph Neural Networks for Drug Discovery Under Distributional Shift </span><a href='https://arxiv.org/pdf/2111.12951.pdf'><span>[paper]</span></a></li><li><span>[ICML 2020 workshop] Evaluating Logical Generalization in Graph Neural Networks </span><a href='https://arxiv.org/pdf/2003.06560.pdf'><span>[paper]</span></a></li></ul><h4 id='dataset'><span>Dataset</span></h4><ul><li><span>[NeurIPS 2021 Workshop] A Closer Look at Distribution Shifts and Out-of-Distribution Generalization on Graphs </span><a href='https://openreview.net/pdf?id=XvgPGWazqRH'><span>[paper]</span></a></li><li><span>[arXiv 2022] DrugOOD: Out-of-Distribution (OOD) Dataset Curator and Benchmark for AI-aided Drug Discovery -- A Focus on Affinity Prediction Problems with Noise Annotations </span><a href='https://arxiv.org/pdf/2201.09637.pdf'><span>[paper]</span></a></li></ul></div></div>



<div id="footer">
    <div id="footer-text"></div>
</div>
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=1u2pc63feHrBeF3TlPyxkBBa3FhX-vSaM6h2NoAoe_c"></script>
</div>



Last updated on Feb. 22, 2022. 
If you notice some related papers missing, do not hesitate to contact us via pull requests at <a href="https://github.com/graph-ood-generalization/graph-ood-generalization.github.io">our repo</a>.
</body></html>
